#+title: Notes

* Running the Language server
pip install 'llama-cpp-python[server]'

python3 -m llama_cpp.server --model models/mistral-7b-instruct-v0.1.Q4_K_M.gguf --chat_format functionary

{
  "messages": [
    {
      "content": "You are a helpful assistant.",
      "role": "system"
    },
    {
      "content": "What's the weather in New York, NY?",
      "role": "user"
    }
  ],
  "tools": [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA"
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                },
                "required": ["location"]
            }
        }
    }
  ],
  "tool_choice": "auto"
}
